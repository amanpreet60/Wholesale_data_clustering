{
 "cells": [
  {
   "cell_type": "raw",
   "id": "55da0a1c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: STATS/CSE 780 - Homework Assignment 3\n",
    "author: \"Name: Amanpreet Singh (400672477)\"\n",
    "date: 2025/11/07\n",
    "format: pdf\n",
    "header-includes:\n",
    "   - \\usepackage{amsmath}\n",
    "   - \\usepackage{bbm}\n",
    "   - \\usepackage{array}\n",
    "   - \\usepackage{multirow}\n",
    "   - \\usepackage{graphicx}\n",
    "   - \\usepackage{float}\n",
    "   - \\usepackage{apacite}\n",
    "   - \\newcommand{\\bc}{\\color{black}}\n",
    "   - \\newcommand{\\blc}{\\color{blue}}\n",
    "   - \\newcommand{\\mX}{\\mbox{\\textbf{X}}}\n",
    "   - \\usepackage[T1]{fontenc}\n",
    "execute: \n",
    "  echo: true\n",
    "fontsize: 11pt\n",
    "geometry: margin = 1in\n",
    "linestretch: 1.4\n",
    "bibliography: STATS780.bib \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e00130",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551dede",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "# Assignment Questions\n",
    "\n",
    "## 1. Dataset Selection and Description\n",
    "\n",
    "The dataset used in this study is the Wholesale Customers Dataset, obtained from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/292/wholesale+customers). It contains information about 440 wholesale clients of a Portuguese distributor, with the goal of segmenting customers based on their annual spending patterns. The dataset includes eight attributes, of which six are continuous variables representing annual expenditures on different product categories, Fresh, Milk, Grocery, Frozen, Detergents_Paper, and Delicatessen and two are categorical variables, Channel (Horeca or Retail) and Region (Lisbon, Oporto, or Other). For the purpose of this analysis, the categorical variables were dropped, and only the continuous features were used. The data is clean, with no missing values. The continuous features were scaled using StandardScaler to ensure that all variables contribute equally to the analysis.\n",
    "\n",
    "Clustering is suitable for this dataset because the primary objective is to group customers with similar purchasing behaviors without any predefined labels. By identifying natural groupings, businesses can better understand customer segments, tailor marketing strategies, and optimize inventory planning.\n",
    "\n",
    "## 2. Cluster Analysis\n",
    "\n",
    "### Hierarchical Clustering\n",
    "\n",
    "The Agglomerative Hierarchical Clustering analysis on the dataset was conducted using various linkage methods to explore how distance metrics affect cluster formation. The dendrograms for Ward, Complete, and Single linkages reveal distinct hierarchical structures, with Ward linkage producing more balanced, compact clusters, while Single linkage exhibited the typical “chaining” effect, where points are sequentially linked based on minimal pairwise distances rather than overall group cohesion. Although the Single and Complete linkage methods achieved the highest silhouette score of 0.8638 for two clusters, this can be misleading, the high score reflects the presence of very tight subgroups and large inter-cluster gaps, not necessarily meaningful cluster compactness. In practice, such chaining can occur when a few customers have extreme spending behaviors that “bridge” between groups, artificially connecting distant observations into one elongated cluster. In contrast, the Ward linkage with a silhouette score of 0.7925 produced more interpretable clusters by minimizing within-cluster variance. Moreover, increasing the number of clusters to three reduced silhouette scores across all methods, suggesting that the data naturally forms two main customer groups with distinct purchasing patterns\n",
    "\n",
    "![](plots/hclust.png){fig-align=\"center\" width=\"100%\"}\n",
    "\n",
    "### K-Means Clustering\n",
    "\n",
    "Building on the hierarchical clustering results, which showed that the data fits best into two clear clusters, K-Means was used to check if a centroid-based method could find a similar pattern. The results showed slightly better performance for three clusters (silhouette = 0.4583) than for two (silhouette = 0.3998), but both were much lower than the hierarchical scores. This suggests that K-Means could not capture the same strong separation found earlier, likely because customer spending patterns are irregular and not spherical in shape. In real terms, many customers share similar buying habits but differ in overall spending volume, causing overlap between groups.\n",
    "\n",
    "### K-Means Clustering After PCA\n",
    "\n",
    "To further improve clustering performance, Principal Component Analysis (PCA) was applied to reduce dimensionality while retaining around 85% of the explained variance within the first two components. After transforming the data, K-Means clustering was performed on the reduced features. The best result was achieved using two clusters with two principal components, giving a silhouette score of 0.6984, which is lower than the best hierarchical score but significantly higher than K-Means on the original data. This shows that PCA helped remove noise and redundant information, leading to better separation of customers in the reduced space. However, increasing the number of components or clusters did not further improve results, indicating that the main structure of the data can already be captured effectively by two components.\n",
    "\n",
    "## 3. Clustering methods comparisions\n",
    "\n",
    "The clustering analysis reveals notable differences between the methods. First, Agglomerative Clustering produces the most distinct and well-separated clusters, with ward linkage capturing the natural groupings of customers based on spending patterns. In contrast, KMeans shows more overlap between clusters, reflecting its reliance on centroids and the assumption of spherical clusters, which may not match the true distribution of the data. Second, comparing hierarchical clustering with PCA, the latter reduces cluster separation because projecting high-dimensional data into fewer dimensions can obscure subtle differences, whereas Agglomerative Clustering retains the full structure of the data. These comparisons indicate that hierarchical clustering best preserves natural groupings, while KMeans and PCA provide complementary perspectives that highlight global trends and finer variations in customer behavior.\n",
    "\n",
    "## 4. UMAP Visualization and Discussion\n",
    "\n",
    "Compared to Agglomerative Clustering, UMAP captures the overall separation of customers but produces slightly less compact clusters, with some points bridging groups. Its silhouette score of 0.4312 indicates moderate separation, reflecting local overlap caused by the nonlinear embedding. Overall, UMAP provides an intuitive visualization that aligns with hierarchical clustering while highlighting the dataset’s inherent structure and variability.\n",
    "\n",
    "A comparison with the Channel variable shows that Cluster 0 mostly contains Channel 1 customers (248 out of 256) and Cluster 1 mostly contains Channel 2 customers (134 out of 184), suggesting that UMAP clusters roughly correspond to the Horeca vs. Retail segmentation while still capturing some cross-channel variability.\n",
    "\n",
    "![](plots/umap.png){fig-align=\"center\" width=\"40%\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b493985",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa2f0fe",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "\n",
    "::: {#refs}\n",
    ":::\n",
    "\n",
    "[@wholesale_uci]\n",
    "[@jain2010data]\n",
    "[@kaufman2009finding]\n",
    "[@umap2018]\n",
    "[@rousseeuw1987silhouettes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb0263d",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac7748",
   "metadata": {},
   "source": [
    "# Supplemental Material\n",
    "\n",
    "- Note: GitHub Copilot was used to assist with code generation and error handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb31f3",
   "metadata": {},
   "source": [
    "::: {.columns} \n",
    "\n",
    "::: {.column width=\"50%\"} \n",
    "\n",
    "![](plots/pca.png){width=\"50%\"} \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from umap.umap_ import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1da2bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Wholesale customers data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef6703c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13265</td>\n",
       "      <td>1196</td>\n",
       "      <td>4221</td>\n",
       "      <td>6404</td>\n",
       "      <td>507</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22615</td>\n",
       "      <td>5410</td>\n",
       "      <td>7198</td>\n",
       "      <td>3915</td>\n",
       "      <td>1777</td>\n",
       "      <td>5185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel  Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicassen\n",
       "0        2       3  12669  9656     7561     214              2674        1338\n",
       "1        2       3   7057  9810     9568    1762              3293        1776\n",
       "2        2       3   6353  8808     7684    2405              3516        7844\n",
       "3        1       3  13265  1196     4221    6404               507        1788\n",
       "4        2       3  22615  5410     7198    3915              1777        5185"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "698f8369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 440 entries, 0 to 439\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   Channel           440 non-null    int64\n",
      " 1   Region            440 non-null    int64\n",
      " 2   Fresh             440 non-null    int64\n",
      " 3   Milk              440 non-null    int64\n",
      " 4   Grocery           440 non-null    int64\n",
      " 5   Frozen            440 non-null    int64\n",
      " 6   Detergents_Paper  440 non-null    int64\n",
      " 7   Delicassen        440 non-null    int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 27.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a4845fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping categorical variables\n",
    "df = df.drop(columns=[\"Channel\", \"Region\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1e5d9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cde8919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Clusters  Linkage  Silhouette Score\n",
      "        2   single          0.863801\n",
      "        2 complete          0.863801\n",
      "        2  average          0.863801\n",
      "        3   single          0.796648\n",
      "        2     ward          0.792457\n",
      "        3  average          0.767580\n",
      "        3 complete          0.711531\n",
      "        3     ward          0.264609\n"
     ]
    }
   ],
   "source": [
    "# Agglomerative Clustering\n",
    "\n",
    "linkages = ['single', 'ward', 'complete', 'average']\n",
    "clusters = [2, 3]\n",
    "results = []\n",
    "for link in linkages:\n",
    "    for n in clusters:\n",
    "        # 'ward' only supports Euclidean distance, so skip if not allowed\n",
    "        if link == 'ward' and n < 2:\n",
    "            continue\n",
    "        agg = AgglomerativeClustering(n_clusters=n, linkage=link)\n",
    "        labels = agg.fit_predict(X_scaled)\n",
    "        score = silhouette_score(X_scaled, labels)\n",
    "        results.append({'Clusters': n, 'Linkage': link, 'Silhouette Score': score})\n",
    "\n",
    "# make a neat table\n",
    "df_results = pd.DataFrame(results).sort_values(by='Silhouette Score', ascending=False)\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0998eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define linkage methods\n",
    "methods = ['ward', 'complete', 'single']\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "# Generate a subplot for each linkage method\n",
    "for i, method in enumerate(methods, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    Z = linkage(X_scaled, method=method)\n",
    "    dendrogram(Z, no_labels=True)\n",
    "    plt.title(f'{method.capitalize()} Linkage')\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('Distance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "747d868c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Clusters  Model  Silhouette Score\n",
      "        3 KMeans          0.458263\n",
      "        2 KMeans          0.399828\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# test for 2 and 3 clusters\n",
    "for n in [2, 3]:\n",
    "    kmeans = KMeans(n_clusters=n, random_state=42)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    score = silhouette_score(X_scaled, labels)\n",
    "    results.append({'Clusters': n, 'Model': 'KMeans', 'Silhouette Score': score})\n",
    "\n",
    "# make a DataFrame and sort descending\n",
    "df_kmeans = pd.DataFrame(results).sort_values(by='Silhouette Score', ascending=False)\n",
    "print(df_kmeans.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "79e4bca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PCs  Clusters  Silhouette Score\n",
      "   2         2          0.698393\n",
      "   3         2          0.577820\n",
      "   3         3          0.390530\n",
      "   2         3          0.381729\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Try PCA with 2 and 3 components\n",
    "for n_pc in [2, 3]:\n",
    "    pca = PCA(n_components=n_pc)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Cluster on reduced data\n",
    "    for n_clusters in [2, 3]:\n",
    "        kmeans_pca = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        labels = kmeans_pca.fit_predict(X_pca)\n",
    "        score = silhouette_score(X_pca, labels)\n",
    "\n",
    "        results.append({\n",
    "            'PCs': n_pc,\n",
    "            'Clusters': n_clusters,\n",
    "            'Silhouette Score': score\n",
    "        })\n",
    "\n",
    "# Display results\n",
    "df_pca = pd.DataFrame(results).sort_values(by='Silhouette Score', ascending=False)\n",
    "print(df_pca.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a805397",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X_scaled)\n",
    "cum_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(cum_var, 'o-', color='red')\n",
    "plt.axhline(0.9, color='gray', ls='--')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Cumulative PCA Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed83a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP + Clustering + Visualization\n",
    "X_umap = UMAP(n_neighbors=15, min_dist=0.1, random_state=42).fit_transform(X_scaled)\n",
    "labels = AgglomerativeClustering(n_clusters=2, linkage='ward').fit_predict(X_umap)\n",
    "\n",
    "sns.scatterplot(x=X_umap[:,0], y=X_umap[:,1], hue=labels, palette=\"viridis\", s=60, edgecolor='k')\n",
    "plt.title(\"UMAP Projection of Wholesale Customers Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6c4b6cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel    1    2\n",
      "row_0            \n",
      "0        248    8\n",
      "1         50  134\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.crosstab(labels, df['Channel'])\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9911a280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.4312\n"
     ]
    }
   ],
   "source": [
    "print(f\"Silhouette Score: {silhouette_score(X_umap, labels):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umap-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
